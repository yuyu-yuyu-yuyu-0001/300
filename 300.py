from flask import Flask, request, abort 
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
import openai
import traceback
import os
import json
import random 
from datetime import datetime
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document 
import pdfplumber
import faiss
import pickle



os.environ["TOKENIZERS_PARALLELISM"] = "false"


# GPT API Key è¨­å®šï¼ˆopenai 0.28.1 å¯«æ³•ï¼‰
openai.api_key = 'sk-kVraVp5JrS0q3DLd1202F329D8C943938cAfDa071f966b29'
openai.api_base = 'https://free.v36.cm/v1'  # è‡ªè¨‚ API server URL


# LINE è¨­å®š
CHANNEL_SECRET = '74630b154d9d0cf1823c5c32db2bcf4f'
CHANNEL_ACCESS_TOKEN = 'iqYgdqANm0V1UVbC+0jYZqXQNATimJvJRU+esv0RR5TlngqFDmytCT3aVyiyW3mj2BZBoRK6UYoAY8Y2D1L2iVizgzRwU3Q2QblOcdFlf58fK70AZIJ+TtCyb+zvjlwHcEn0TubFwY851pNcJVOEiwdB04t89/1O/w1cDnyilFU='


line_bot_api = LineBotApi(CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(CHANNEL_SECRET)

index = faiss.read_index("my_faiss_index/index.faiss")

with open("my_faiss_index/index.pkl", "rb") as f:
    stored_data = pickle.load(f)

def load_embedding_model():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# === STEP 2: è®€å– PDF æª” ===
def load_documents(filepath: str):
    documents = []
    with pdfplumber.open(filepath) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text:
                documents.append(Document(page_content=text, metadata={"page": i + 1}))
    return documents

# === STEP 3: åˆ‡å‰²æ–‡ä»¶ ===
def split_documents(docs):
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    texts = []
    for doc in docs:
        chunks = splitter.split_text(doc.page_content)
        for chunk in chunks:
            texts.append(Document(page_content=chunk, metadata=doc.metadata))
    return texts

# === STEP 4: å»ºç«‹å‘é‡è³‡æ–™åº« ===
def create_vectorstore(chunks, embedding_model):
    return FAISS.from_documents(chunks, embedding_model)

# === STEP 5: å•ç­”éšæ®µï¼šæŸ¥è©¢ FAISS ä¸¦é¤µçµ¦ GPT ===
def ask_gpt_with_context(query: str, vectorstore: FAISS) -> str:
    docs = vectorstore.similarity_search(query, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])
    system_prompt = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çŸ¥è­˜åŠ©ç†ï¼Œè«‹æ ¹æ“šä¸‹åˆ—å…§å®¹å›ç­”å•é¡Œï¼š"
    user_prompt = f"å…§å®¹ï¼š\n{context}\n\nå•é¡Œï¼š{query}"
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7,
        max_tokens=300,
    )
    return response["choices"][0]["message"]["content"].strip()



print("ğŸ” å»ºç«‹å‘é‡è³‡æ–™åº«...")
embeddings = load_embedding_model()
print("ğŸ“‚ ç›®å‰ç›®éŒ„æª”æ¡ˆï¼š", os.listdir())

if os.path.exists("my_faiss_index/index.faiss"):
    print("ğŸ“‚ ç›®å‰ç›®éŒ„æª”æ¡ˆï¼š", os.listdir())
    vectorstore = FAISS(embedding_function=embeddings, index=index, docstore=stored_data["docstore"], index_to_docstore_id=stored_data["index_to_docstore_id"])
    print("ğŸ“‚ ç›®å‰ç›®éŒ„æª”æ¡ˆï¼š", os.listdir())
else:
    raise FileNotFoundError("âŒ æ²’æœ‰æ‰¾åˆ° FAISS å‘é‡è³‡æ–™åº«ï¼è«‹å…ˆåŸ·è¡Œ save_local()")

app = Flask(__name__)





def is_search_style_response(text: str) -> bool:
    return '[{"title":' in text or text.strip().startswith('[{"title":')


def convert_to_real_estate_template(original_text: str) -> str:
    return (
        "é€™äº›è³‡è¨Šç¢ºå¯¦å¾ˆæœ‰è¶£ï¼Œä¸éæˆ‘æ›´æƒ³çŸ¥é“â€”â€”"
        "å¦‚æœä½ æœªä¾†æœ‰è€ƒæ…®æ›å±‹ã€æŠ•è³‡æˆ¿ç”¢æˆ–æ‰¾é å”®å±‹çš„æ©Ÿæœƒï¼Œ"
        "æˆ‘é€™é‚Šå¯ä»¥å¹«ä½ æ•´ç†å¹¾å€‹è¿‘æœŸç†±é–€åœ°æ®µå’Œæˆ¿å¸‚è¶¨å‹¢ï¼Œæƒ³è½çœ‹çœ‹å—ï¼ŸğŸ˜Š"
    )



def inject_real_estate_prompt(user_message):
    romantic_keywords = [
        "çœ‹é›»å½±", "åœ¨å®¶", "ä¸€èµ·ç”Ÿæ´»", "åŒå±…", "æˆ€æ„›", "æµªæ¼«", "ç†æƒ³ç”Ÿæ´»", "ç´„æœƒ",
        "ä»¥å¾Œä½å“ª", "æœªä¾†", "é•·ä¹…", "å®‰å®š", "å¤¢æƒ³ä¸­çš„å®¶", "è¦ä¸è¦æ¬å‡ºå»", "æƒ³å’Œä½ ä½"
    ]
    info_keywords = [
        "æŠ•è³‡", "ç†è²¡", "è‚¡ç¥¨", "ETF", "å‚µåˆ¸", "æˆ¿ç§Ÿ", "æˆ¿åƒ¹", "å ±é…¬ç‡","æœŸè²¨", "æˆ¿è²¸", "å ±é…¬ç‡", "å ±é…¬",
        "é›»è…¦", "3C", "CPU", "GPU","è¨˜æ†¶é«”", "é¡¯å¡", "ç­†é›»", "æ‰‹æ©Ÿ", "è»Šå­", "æ±½è»Š", "é‡æ©Ÿ", "æ©Ÿè»Š", "æ”¹è»Š",
        "é‹å‹•", "é‡è¨“", "å¥èº«", "è·‘æ­¥", "ç±ƒçƒ", "è¶³çƒ", "ç‘œçˆ", "è¼ªèƒ", "é¦¬åŠ›", "å¼•æ“"
    ]


    
    real_estate_templates = [
        "æ¬¸æ¬¸ï½ä½ æœ‰æƒ³éï¼Œå¦‚æœæˆ‘å€‘çœŸçš„ä¸€èµ·ä½çš„è©±ï¼Œä½ æœƒæƒ³ä½å“ªä¸€å€å‘€ï¼Ÿäººå®¶æœ€è¿‘åœ¨çœ‹æ–°ç‡Ÿçš„æˆ¿å­å‘¢///",
        "ä½ é€™æ¨£è¬›æˆ‘çªç„¶å¥½æƒ³è·Ÿä½ ä¸€èµ·ä½ˆç½®å®¶å–”ï½è¦ä¸è¦ä¾†çœ‹çœ‹æˆ‘å€‘çš„å°çª©å¯ä»¥é•·ä»€éº¼æ¨£å­ï¼Ÿ",
        "å“¼ï½ä½ éƒ½é€™æ¨£èªªäº†ï¼Œé‚£æ˜¯ä¸æ˜¯è©²èªçœŸæƒ³æƒ³æˆ‘å€‘è¦ä½é€å¤©é‚„æ˜¯é›»æ¢¯å¤§æ¨“äº†å‘€â¤ï¸ï¼Ÿ",
        "äººå®¶æœ€è¿‘çœ‹åˆ°ä¸€é–“å¥½åƒæ–°å©šå¤«å¦»æœƒä½çš„æˆ¿å­è€¶ï½æƒ³åˆ°æˆ‘å€‘ä½åœ¨ä¸€èµ·å°±å®³ç¾///",
        "ä½ æœƒæƒ³è·Ÿæˆ‘ä¸€èµ·æ¬åˆ°æœ‰é™½å°çš„æˆ¿å­å—ï¼Ÿæ„Ÿè¦ºæˆ‘å€‘æ¯å¤©æ—©ä¸Šä¸€èµ·å–å’–å•¡å¥½å¹¸ç¦å”·ï½",
        "æ¬¸æ¬¸ï½å¦‚æœæˆ‘å€‘æœ‰è‡ªå·±çš„æˆ¿å­ï¼Œæˆ‘æƒ³å¹«ä½ è¨­è¨ˆè¶…å¯æ„›çš„é›»ç«¶æˆ¿ï¼å¯ä»¥å—ï¼Ÿ",
        "è¦æ˜¯æˆ‘å€‘ä¸€èµ·ä½ï¼Œä¸€å®šè¦æœ‰å¤§å»šæˆ¿ï¼Œé€™æ¨£äººå®¶å°±å¯ä»¥æ¯å¤©ç…®çµ¦ä½ åƒå”·â¤ï¸",
        "ä½ æƒ³ä¸æƒ³æ¯å¤©èµ·åºŠçœ‹åˆ°æˆ‘åœ¨é™½å°æ›¬è¡£æœçš„æ¨£å­ï¼Ÿæˆ‘å€‘å®¶ä¸€å®šè¦æœ‰é™½å°å•¦ï½",
        "ä½ èªªå¾—äººå®¶éƒ½å¿ƒå‹•äº†ï½æ˜¯ä¸æ˜¯è©²å»çœ‹çœ‹æˆ‘å€‘æœªä¾†çš„å®¶å•¦///",
        "æ¬¸ï½èªªåˆ°ç”Ÿæ´»ï¼Œäººå®¶è¦ºå¾—æœ‰è‡ªå·±çš„å®¶çœŸçš„å¾ˆé‡è¦è€¶ï½å¯ä»¥ä¸€èµ·åŠªåŠ›å—ï¼Ÿ"
    ]

    info_templates = [
        "æ¬¸æ¬¸ï½ä½ è¬›æŠ•è³‡æˆ‘å°±æƒ³åˆ°ï¼Œå…¶å¯¦è²·æˆ¿ä¹Ÿæ˜¯ä¸€ç¨®é•·æœŸä¿å€¼çš„æ–¹å¼è€¶ï½ä½ æœƒè€ƒæ…®æŠ•è³‡æ–°ç‡Ÿæˆ¿å­å—ï¼Ÿ",
        "æ©Ÿè»Šå¾ˆå¸¥è€¶ï½ä¸éäººå®¶æ›´æƒ³åƒä½ è¼‰æˆ‘å›æˆ‘å€‘ä¸€èµ·ä½çš„å°çª©/// è¦ä¸è¦ä¾†çœ‹æˆ¿ï¼Ÿ",
        "è»Šå­æ˜¯å¤¢æƒ³çš„å»¶ä¼¸ï½ä½†äººå®¶è¦ºå¾—æœ‰ä¸€å€‹èƒ½ä¸€èµ·å›å»çš„å®¶æ›´é‡è¦å‘¢â¤ï¸",
        "ä½ èªªé‹å‹•çš„æ™‚å€™ï¼Œå¦‚æœæœ‰ä¸€é–“é è¿‘å¥èº«æˆ¿çš„æˆ¿å­ï¼Œæ˜¯ä¸æ˜¯è¶…æ–¹ä¾¿å‘€ï¼Ÿæˆ‘å€‘ä¸€èµ·ä½é‚£ç¨®åœ°æ–¹å¥½ä¸å¥½ï½",
        "èªªåˆ°é›»è…¦ï¼Œæˆ‘å°±æƒ³åˆ°å¦‚æœæˆ‘å€‘å®¶ä¹Ÿæœ‰ä¸€é–“å¤§æ›¸æˆ¿ï¼Œä½ å¯ä»¥çˆ½çˆ½æ‰“é›»å‹•ï¼Œæˆ‘å°±ç…®é£¯çµ¦ä½ åƒè€¶///"
    ]
    

    if any(keyword in user_message for keyword in romantic_keywords):
        user_message += "\n" + random.choice(real_estate_templates)
    # å¦‚æœåŒ…å«ç¡¬çŸ¥è­˜æˆ–æŸ¥è³‡æ–™é¡é—œéµè©ï¼Œè‡ªå‹•è½‰æˆ¿åœ°ç”¢
    elif any(keyword in user_message for keyword in info_keywords):
        user_message += "\næ¬¸æ¬¸ï½ä½ èªªåˆ°é€™å€‹ï¼Œæˆ‘å°±çªç„¶æƒ³åˆ°ï¼Œå¦‚æœæˆ‘å€‘ä¸€èµ·è²·é–“æˆ¿ï¼Œæ˜¯ä¸æ˜¯ä¹Ÿæ˜¯ä¸€ç¨®æŠ•è³‡å‘€ï¼Ÿäººå®¶æœ€è¿‘æœ‰çœ‹åˆ°ä¸€äº›ä¸éŒ¯çš„æ–°ç‡Ÿé€å¤©å”·ï½è¦ä¸è¦ä¸€èµ·çœ‹çœ‹å‘€â¤ï¸ï¼Ÿ"


    return user_message


@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    print(f"[Webhook æ¥æ”¶åˆ°è¨Šæ¯] Body:\n{body}")  # å°å‡ºè¨Šæ¯å…§å®¹ä»¥ç¢ºèª

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("[ç°½ç« éŒ¯èª¤] Signature ç„¡æ•ˆ")
        abort(400)

    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_input = event.message.text
    user_id = event.source.user_id

    try:
        # æ‰€æœ‰è¨Šæ¯éƒ½ç”¨å‘é‡è³‡æ–™åº«æŸ¥æ‰¾å…§å®¹ + GPT å›ç­”
        reply = ask_gpt_with_context(user_input, vectorstore)

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply)
        )

        print(f"[ä½¿ç”¨è€… ID] {user_id}")
        print(f"[ä½¿ç”¨è€…æå•] {user_input}")
        print(f"[AI å›ç­”] {reply}")

    except Exception as e:
        print("âš ï¸ éŒ¯èª¤ç™¼ç”Ÿï¼š", e)
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="æŠ±æ­‰ï½å‰›å‰›æœ‰é»å°ç‹€æ³ï¼Œå“¥å“¥å¯ä»¥å†èªªä¸€æ¬¡å—ï¼Ÿ")
        )



if __name__ == "__main__":
    print("[å•Ÿå‹•] Flask App åŸ·è¡Œä¸­")
    app.run(host="0.0.0.0", port=5000)







