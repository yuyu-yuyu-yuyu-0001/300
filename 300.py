from flask import Flask, request, abort 
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
import openai
import traceback
import os
import json
import random 
from datetime import datetime
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document 
import pdfplumber






os.environ["TOKENIZERS_PARALLELISM"] = "false"


# GPT API Key è¨­å®šï¼ˆopenai 0.28.1 å¯«æ³•ï¼‰
openai.api_key = 'sk-kVraVp5JrS0q3DLd1202F329D8C943938cAfDa071f966b29'
openai.api_base = 'https://free.v36.cm/v1'  # è‡ªè¨‚ API server URL


# LINE è¨­å®š
CHANNEL_SECRET = '74630b154d9d0cf1823c5c32db2bcf4f'
CHANNEL_ACCESS_TOKEN = 'iqYgdqANm0V1UVbC+0jYZqXQNATimJvJRU+esv0RR5TlngqFDmytCT3aVyiyW3mj2BZBoRK6UYoAY8Y2D1L2iVizgzRwU3Q2QblOcdFlf58fK70AZIJ+TtCyb+zvjlwHcEn0TubFwY851pNcJVOEiwdB04t89/1O/w1cDnyilFU='


line_bot_api = LineBotApi(CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(CHANNEL_SECRET)


def load_embedding_model():
    return HuggingFaceEmbeddings(model_name="shibing624/text2vec-base-multilingual")

# === STEP 2: è®€å– PDF æª” ===
def load_documents(filepath: str):
    documents = []
    with pdfplumber.open(filepath) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text:
                documents.append(Document(page_content=text, metadata={"page": i + 1}))
    return documents

# === STEP 3: åˆ‡å‰²æ–‡ä»¶ ===
def split_documents(docs):
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    texts = []
    for doc in docs:
        chunks = splitter.split_text(doc.page_content)
        for chunk in chunks:
            texts.append(Document(page_content=chunk, metadata=doc.metadata))
    return texts

# === STEP 4: å»ºç«‹å‘é‡è³‡æ–™åº« ===
def create_vectorstore(chunks, embedding_model):
    return FAISS.from_documents(chunks, embedding_model)



# æ­¥é©Ÿ 5ï¼šä½¿ç”¨è€…æå• â†’ ç›¸ä¼¼å…§å®¹ â†’ é¤µçµ¦ ChatGPT
def ask_gpt_with_context(query: str, vectorstore: FAISS) -> str:
    # å–å¾—æœ€ç›¸ä¼¼çš„æ–‡ä»¶å…§å®¹
    docs = vectorstore.similarity_search(query, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])

    # å»ºæ§‹ ChatGPT æå•å…§å®¹
    system_prompt = "ä½ æ˜¯ä¸€å€‹çŸ¥è­˜è±å¯Œçš„å°ˆæ¥­åŠ©ç†ï¼Œæ ¹æ“šä»¥ä¸‹å…§å®¹å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚"
    user_prompt = f"ä»¥ä¸‹æ˜¯ç›¸é—œçŸ¥è­˜å…§å®¹ï¼š\n\n{context}\n\nä½¿ç”¨è€…å•é¡Œï¼š{query}"

    # ä½¿ç”¨ ChatGPTï¼ˆOpenAI 0.28.1 æ–¹å¼ï¼‰
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.98,
        max_tokens=300,
    )
    return response["choices"][0]["message"]["content"].strip()




print("ğŸ” å»ºç«‹å‘é‡è³‡æ–™åº«...")
embeddings = load_embedding_model()

print("ğŸ“„ è¼‰å…¥çŸ¥è­˜æ–‡ä»¶...")
docs = load_documents("00.pdf")

print("âœ‚ï¸ åˆ†å‰²æ–‡ä»¶...")
chunks = split_documents(docs)

print("ğŸ” å»ºç«‹å‘é‡è³‡æ–™åº«...")
embeddings = load_embedding_model()
vectorstore = create_vectorstore(chunks, embeddings)

app = Flask(__name__)







@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    print(f"[Webhook æ¥æ”¶åˆ°è¨Šæ¯] Body:\n{body}")  # å°å‡ºè¨Šæ¯å…§å®¹ä»¥ç¢ºèª

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("[ç°½ç« éŒ¯èª¤] Signature ç„¡æ•ˆ")
        abort(400)

    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_input = event.message.text
    user_id = event.source.user_id

    try:
        # æ‰€æœ‰è¨Šæ¯éƒ½ç”¨å‘é‡è³‡æ–™åº«æŸ¥æ‰¾å…§å®¹ + GPT å›ç­”
        reply = ask_gpt_with_context(user_input, vectorstore)

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply)
        )

        print(f"[ä½¿ç”¨è€… ID] {user_id}")
        print(f"[ä½¿ç”¨è€…æå•] {user_input}")
        print(f"[AI å›ç­”] {reply}")

    except Exception as e:
        print("âš ï¸ éŒ¯èª¤ç™¼ç”Ÿï¼š", e)
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="æŠ±æ­‰ï½å‰›å‰›æœ‰é»å°ç‹€æ³ï¼Œå“¥å“¥å¯ä»¥å†èªªä¸€æ¬¡å—ï¼Ÿ")
        )



if __name__ == "__main__":
    print("[å•Ÿå‹•] Flask App åŸ·è¡Œä¸­")
    app.run(host="0.0.0.0", port=5000)







